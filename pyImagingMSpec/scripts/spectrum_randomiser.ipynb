{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "sys.path.append('/Users/palmer/Documents/python_codebase/')\n",
    "from pyImagingMSpec.hdf5.IMSdataset import IMSdataset\n",
    "from pyMS import centroid_detection\n",
    "from pyImzML import ImzMLParser\n",
    "import h5py\n",
    "import datetime\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "the idea is to load each spectrum one-at-a-time and then randomise the intensities across the existing m/zs. another version of this could add some random offset to each m/z.\n",
    "\n",
    "not sure if it's best to randomise intensities each spectrum or mzs across the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded spectra\n",
      "file loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/site-packages/numpy/core/_methods.py:71: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from pyImagingMSpec.hdf5.inMemoryIMS_hdf5 import inMemoryIMS_hdf5\n",
    "### Provide file names\n",
    "filename_IMShdf5_in = '/Users/palmer/Documents/tmp_data/RatBrain_IMS/RatBrain_2013_09_20_centroids_IMS.hdf5'\n",
    "filename_IMShdf5_out = '/Users/palmer/Documents/tmp_data/RatBrain_IMS/RatBrain_2013_09_20_centroids_IMS copy1.hdf5'\n",
    "\n",
    "### Open files\n",
    "#create file, truncate if exists\n",
    "IMS_dataset=inMemoryIMS_hdf5(filename_IMShdf5_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.93\\% complete\n",
      "fin\n"
     ]
    }
   ],
   "source": [
    "filename_IMShdf5_out = '/Users/palmer/Documents/tmp_data/RatBrain_IMS/RatBrain_2013_09_20_centroids_IMS copy1.hdf5'\n",
    "\n",
    "with h5py.File(filename_IMShdf5_out,'w') as f_out:\n",
    "    #with h5py.File(filename_IMShdf5_in,'r') as f_in:\n",
    "    ### Provide some file info\n",
    "    # note, there is support for multiple sample types within a file but the code must be updated.\n",
    "    sample_name = 'Rat Brain' \n",
    "    sample_source = 'Palmer'\n",
    "    sample_preparation = 'thin section on ITO slide'\n",
    "    maldi_matrix = 'DHB'\n",
    "    matrix_application = 'sublimation'\n",
    "    ### Open files\n",
    "    ### make root groups for output data\n",
    "    spectral_data = f_out.create_group('spectral_data')\n",
    "    spatial_data = f_out.create_group('spatial_data')\n",
    "    shared_data = f_out.create_group('shared_data')\n",
    "\n",
    "    ### populate common variables - can hardcode as I know what these are for h5 data\n",
    "    # parameters\n",
    "    instrument_parameters_1 = shared_data.create_group('instrument_parameters/001')\n",
    "    instrument_parameters_1.attrs['instrument name'] = 'Solarix'\n",
    "    instrument_parameters_1.attrs['analyser type'] = 'Bruker'\n",
    "    instrument_parameters_1.attrs['data conversion'] = 'hdf5->hdf5 randomised:'+str(datetime.datetime.now())\n",
    "    # m/z axis\n",
    "        #will centroid data so this doesn't exist\n",
    "    # ROIs\n",
    "        #todo - determine and propagate all ROIs\n",
    "    roi_1 = shared_data.create_group('regions_of_interest/001')\n",
    "    roi_1.attrs['name'] = 'root region'\n",
    "    roi_1.attrs['parent'] = ''\n",
    "    # Sample\n",
    "        #todo - not write empty properties\n",
    "    sample_1 = shared_data.create_group('samples/001')\n",
    "    sample_1.attrs['name'] = sample_name\n",
    "    sample_1.attrs['source'] = sample_source\n",
    "    sample_1.attrs['preparation'] = sample_preparation\n",
    "    sample_1.attrs['MALDI matrix'] = maldi_matrix\n",
    "    sample_1.attrs['MALDI matrix application'] = matrix_application\n",
    "\n",
    "    ### write spectra\n",
    "\n",
    "    n=0;\n",
    "    for i,idx in enumerate(IMS_dataset.index_list):\n",
    "        ## rename as I'm using old code :S\n",
    "        spot = i\n",
    "        key=str(idx)\n",
    "        coords = IMS_dataset.coords[idx]\n",
    "        ## make new spectrum\n",
    "        spec=IMS_dataset.get_spectrum(idx)\n",
    "        mzs_list,intensity_list = spec.get_spectrum(source='centroids')\n",
    "        np.random.shuffle(intensity_list)\n",
    "        # add intensities\n",
    "        this_spectrum = spectral_data.create_group(key)\n",
    "        try:\n",
    "            this_intensities = this_spectrum.create_dataset('centroid_intensities',data=np.float32(intensity_list),compression=\"gzip\",compression_opts=9)\n",
    "        except:\n",
    "            print ints\n",
    "            print intensity_list\n",
    "            raise\n",
    "        # add coordinates\n",
    "        if len(coords)==2:\n",
    "            coords = (coords[0],coords[1],0)\n",
    "        this_coordiantes = this_spectrum.create_dataset('coordinates',data=(coords[0],coords[1],coords[2]))\n",
    "        ## link to shared parameters\n",
    "        # mzs\n",
    "        this_mzs = this_spectrum.create_dataset('centroid_mzs',data=np.float64(mzs_list),compression=\"gzip\",compression_opts=9)\n",
    "\n",
    "        ###\n",
    "        # ROI\n",
    "        this_spectrum['ROIs/001'] = h5py.SoftLink('/shared_data/regions_of_interest/001')\n",
    "        # Sample\n",
    "        this_spectrum['samples/001'] = h5py.SoftLink('/shared_data/samples/001')\n",
    "        # Instrument config\n",
    "        this_spectrum['instrument_parameters'] = h5py.SoftLink('/shared_data/instrument_parameters/001')\n",
    "        n+=1\n",
    "        if np.mod(n,10)==0:\n",
    "            clear_output(wait=True)\n",
    "            print '{:3.2f}\\% complete\\r'.format(100.*n/len(IMS_dataset.coords),end=\"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "print 'fin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
